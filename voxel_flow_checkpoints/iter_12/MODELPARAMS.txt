batch_size=16
learning_rate=0.0001
lambda_motion=0.01
lambda_mask=0.005
epsilon=0.001

Slow motion video
Charbonnier loss
Charbonnier regularization
Multi-scale

input_images_128 = tf.image.resize_bilinear(input_images, [128, 128])
conv_1b = slim.conv2d(input_images_128, 12, [5, 5], stride=1, scope='conv1b')
pool_1b = slim.max_pool2d(conv_1b, [2, 2], scope='pool1b')
conv_2b = slim.conv2d(pool_1b, 24, [5, 5], stride=1, scope='conv2b')
pool_2b = slim.max_pool2d(conv_2b, [2, 2], scope='pool2b')
conv_3b = slim.conv2d(pool_2b, 48, [3, 3], stride=1, scope='conv3b')
pool_3b = slim.max_pool2d(conv_3b, [2, 2], scope='pool3b')
bottleneck_b = slim.conv2d(pool_3b, 96, [3, 3], stride=1, scope='bottleneck_b')
# decoders
upsamp_1b = tf.image.resize_bilinear(bottleneck_b, [32, 32])
deconv_1b = slim.conv2d(tf.concat([upsamp_1b, conv_3b], axis=3), 
            48, [3, 3], stride=1, scope='deconv4b')
upsamp_2b = tf.image.resize_bilinear(deconv_1b, [64, 64])
deconv_2b = slim.conv2d(tf.concat([upsamp_2b, conv_2b], axis=3), 
            24, [3, 3], stride=1, scope='deconv5b')
# upsample to input dimensions
upsamp_3b = tf.image.resize_bilinear(deconv_2b, [128, 128])
deconv_3b = slim.conv2d(tf.concat([upsamp_3b, conv_1b], axis=3), 
            24, [5, 5], stride=1, scope='deconv6b')
# concatenate w/ coarser scale
deconv_64b = tf.image.resize_bilinear(flow_64, [128, 128])
deconv_64b = slim.conv2d(deconv_64b, 24, [128, 128], stride=1, scope='deconv_64b')
flow_128 = slim.conv2d(tf.concat([deconv_64b, deconv_3b], axis=3), 3,
                     [5, 5], stride=1, scope='flow_128')


# scale 256 x 256
# encoders
conv_1a = slim.conv2d(input_images, 16, [5, 5], stride=1, scope='conv1a')
pool_1a = slim.max_pool2d(conv_1a, [2, 2], scope='pool1a')
conv_2a = slim.conv2d(pool_1a, 32, [5, 5], stride=1, scope='conv2a')
pool_2a = slim.max_pool2d(conv_2a, [2, 2], scope='pool2a')
conv_3a = slim.conv2d(pool_2a, 64, [3, 3], stride=1, scope='conv3a')
pool_3a = slim.max_pool2d(conv_3a, [2, 2], scope='pool3a')
bottleneck_a = slim.conv2d(pool_3a, 128, [3, 3], stride=1, scope='bottleneck_a')
# decoders
upsamp_1a = tf.image.resize_bilinear(bottleneck_a, [64, 64])
deconv_1a = slim.conv2d(tf.concat([upsamp_1a, conv_3a], axis=3), 
            64, [3, 3], stride=1, scope='deconv4a')
upsamp_2a = tf.image.resize_bilinear(deconv_1a, [128, 128])
deconv_2a = slim.conv2d(tf.concat([upsamp_2a, conv_2a], axis=3), 
            32, [3, 3], stride=1, scope='deconv5a')
# upsample to input dimensions
upsamp_3a = tf.image.resize_bilinear(deconv_2a, [256, 256])

deconv_256 = slim.conv2d(tf.concat([upsamp_3a, conv_1a], axis=3), 
            32, [5, 5], stride=1, scope='deconv6a')
# concatenate w/ coarser scale
deconv_64a = tf.image.resize_bilinear(flow_64, [256, 256])
deconv_64a = slim.conv2d(deconv_64a, 32, [256, 256], stride=1, scope='deconv_64a')
deconv_128 = tf.image.resize_bilinear(flow_128, [256, 256])
deconv_128 = slim.conv2d(deconv_128, 32, [5, 5], stride=1, scope='deconv_128')
conv_concat = slim.conv2d(tf.concat([deconv_64a, deconv_128, deconv_256], axis=3),
                    64, [5, 5], stride=1, scope='conv_concat')